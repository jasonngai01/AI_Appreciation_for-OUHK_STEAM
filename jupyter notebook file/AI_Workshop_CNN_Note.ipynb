{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI_Workshop_CNN_Note.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAGGLDVVIyLs"
      },
      "source": [
        "# 1. How many types of Deep Learning (深度學習)? What are these?\n",
        "\n",
        "\n",
        "Here is a visual representation of the seven:\n",
        "\n",
        "<img src =\"https://i.imgur.com/EAl47rp.png\" width = \" 1200\" />\n",
        "\n",
        "\n",
        "1. **Feed Forward Neural Networks (FFNNs)** - classification and regression based on features. \n",
        "\n",
        "2. **Convolutional Neural Networks (CNNs)** - image classification, object detection, video action recognition, etc. \n",
        "\n",
        "3. **Recurrent Neural Networks (RNNs)** - language modeling, speech recognition/generation, etc. \n",
        "\n",
        "4. **Encoder Decoder Architectures** - semantic segmentation, machine translation, etc. \n",
        "\n",
        "5. **Autoencoder** - unsupervised embeddings, denoising, etc.\n",
        "\n",
        "6. **Generative Adversarial Networks (GANs)** - unsupervised generation of realistic images, etc. \n",
        "\n",
        "7. **Deep Reinforcement Learning** - game playing, robotics in simulation, self-play, neural arhitecture search, etc. \n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUPTYeGPIyLw"
      },
      "source": [
        "## 2.  Regression and Classification in Machine Learning\n",
        "\n",
        "<img src=\"https://i.imgur.com/vvSoAzg.jpg\" alt=\"classification_regression\" width=\"600\"/>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9u5qbWfMLEZQ"
      },
      "source": [
        "###2A: Classification Predictive Modeling (分類預測建模)\n",
        "\n",
        "\n",
        "1. Classification predictive modeling is the task of approximating a mapping function (f) from input variables (輸入變量) (X) to discrete output variables (離散輸出變量) (y).\n",
        "\n",
        "2. The output variables are often called labels or categories (標籤或類別). The mapping function (映射函數) predicts the class or category for a given observation.\n",
        "\n",
        "3. For example, an email of text can be classified as belonging to one of two classes: “spam“ and “not spam“.\n",
        "\n",
        "4. A classification problem requires that examples be classified into one of two or more classes.\n",
        "\n",
        "5. A classification can have real-valued ((實值) or discrete input variables (離散輸入變量).\n",
        "\n",
        "6. A problem with two classes is often called a two-class or binary classification (二元分類) problem.\n",
        "\n",
        "7. A problem with more than two classes is often called a multi-class classification (多類分類) problem.\n",
        "\n",
        "8. The probabilities can be interpreted as the likelihood or confidence (可能性或置信度) of a given example belonging to each class. \n",
        "\n",
        "9. A predicted probability can be converted into (轉換為) a class value by selecting the class label that has the highest probability.\n",
        "\n",
        "10. For example, a specific email of text may be assigned the probabilities of 0.1 as being “spam”(垃圾郵件) and 0.9 as being “not spam”. \n",
        "\n",
        "11. We can convert these probabilities to a class label by selecting the “not spam” label as it has the highest predicted likelihood.\n",
        "\n",
        "12. There are many ways to estimate the skill of a classification predictive model, but perhaps the most common is to calculate the classification accuracy (計算分類準確度).\n",
        "\n",
        "13. The classification accuracy is the percentage of correctly classified examples out of all predictions made (所有預測中正確分類示例的百分比).\n",
        "\n",
        "14. For example, if a classification predictive model made 5 predictions and 3 of them were correct and 2 of them were incorrect, then the classification accuracy of the model based on just these predictions would be:\n",
        "\n",
        "\n",
        "```\n",
        "accuracy = correct predictions / total predictions * 100\n",
        "accuracy = 3 / 5 * 100\n",
        "accuracy = 60%\n",
        "```\n",
        "\n",
        "15. An algorithm that is capable of learning a classification predictive model is called a classification algorithm (分類算法)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wbd44FLLOqS"
      },
      "source": [
        "### 2B: Regression Predictive Modeling (回歸預測建模)\n",
        "\n",
        "1. Regression predictive modeling is the task of approximating a mapping function (映射函數) (f) from input variables (輸入變量) (X) to a continuous output variable (連續輸出變量) (y).\n",
        "\n",
        "2. A continuous output variable (連續輸出變量) is a real-value (實數值), such as an integer or floating point value. \n",
        "\n",
        "3. These are often quantities (數量), such as amounts and sizes.\n",
        "\n",
        "4. For example, a house may be predicted to sell for a specific dollar value, perhaps in the range of *100,000 dollars* to *200,000 dollars*.\n",
        "\n",
        "5. A regression problem requires the prediction of a quantity (數量預測).\n",
        "\n",
        "6. A regression can have real valued or discrete input variables (離散輸入變量).\n",
        "\n",
        "7. A problem with multiple input variables (多個輸入變量) is often called a multivariate regression problem.\n",
        "\n",
        "8. A regression problem where input variables are ordered by time is called a time series forecasting problem (時間序列預測問題).\n",
        "\n",
        "9. Because a regression predictive model predicts a quantity, the skill of the model must be reported as an error (錯誤) in those predictions.\n",
        "\n",
        "10. For example, if a regression predictive model made 2 predictions, one of 1.5 where the expected value is 1.0 and another of 3.3 and the expected value is 3.0, then the RMSE would be:\n",
        "\n",
        "\n",
        "```\n",
        "RMSE = sqrt(average(error^2))\n",
        "RMSE = sqrt(((1.0 - 1.5)^2 + (3.0 - 3.3)^2) / 2)\n",
        "RMSE = sqrt((0.25 + 0.09) / 2)\n",
        "RMSE = sqrt(0.17)\n",
        "RMSE = 0.412\n",
        "```\n",
        "\n",
        "11. A benefit of RMSE is that the units of the error score are in the same units as the predicted value.\n",
        "\n",
        "12. An algorithm that is capable of learning a regression predictive model is called a regression algorithm.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXI78-n7MVdH"
      },
      "source": [
        "### 2C: Classification vs Regression\n",
        "\n",
        "<img src=\"https://static.javatpoint.com/tutorial/machine-learning/images/regression-vs-classification-in-machine-learning.png\" alt=\"classification_regression\" width=\"600\"/>\n",
        "\n",
        "1. Classification predictive modeling problems are different from regression predictive modeling problems.\n",
        "\n",
        "2. Classification is the task of predicting a discrete class label.(預測離散類標籤)\n",
        "\n",
        "3. Regression is the task of predicting a continuous quantity. (預測連續數量)\n",
        "\n",
        "4. Importantly, the way that we evaluate classification and regression predictions varies and does not overlap (重疊).\n",
        "\n",
        "5. Classification predictions can be evaluated using accuracy (準確度), whereas regression predictions cannot.\n",
        "\n",
        "6. Regression predictions can be evaluated using root mean squared error (均方根誤差), whereas classification predictions cannot.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ihr1X8jqrca_"
      },
      "source": [
        "#2. Convolutional neural network (卷積神經網絡)\n",
        "\n",
        "1. In deep learning, a convolutional neural network (CNN, or ConvNet) is a class of deep neural network, most commonly applied to analyze visual imagery (分析視覺圖像).\n",
        "\n",
        "2. They are also known as shift invariant (移不變量) or space invariant (空間不變) artificial neural networks (SIANN), based on the shared-weight architecture (共享權重架構) of the convolution kernels (卷積核) or filters that slide along input features and provide translation equivariant responses (翻譯等變反應) known as feature maps (特徵圖).\n",
        "\n",
        "3. CNN has 2 major features:\n",
        "\n",
        "> 1. Can effectively reduce the dimensionality (維度) of a large amount of data into a small amount of data\n",
        "\n",
        "> 2. Ability to effectively retain the image characteristics (圖像特徵), in line with the principles of image processing\n",
        "\n",
        "4. They have applications in image and video recognition (圖像和視頻識別), image classification (圖像分類), image segmentation (圖像分割), medical image analysis (醫學圖像分析)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2DrAqt_sqwR"
      },
      "source": [
        "##2A:　What problem did CNN solve?\n",
        "\n",
        "Before the advent of CNN, images were a problem for artificial intelligence for two reasons:\n",
        "\n",
        ">1. The amount of data to be processed by the image is too large, resulting in high cost and low efficiency (數據量過大，成本高，效率低)\n",
        "\n",
        ">2. It is difficult for the image to retain the original features during the digitization process (數字化過程中難以保留原始特徵), resulting in low accuracy of image processing (圖像處理精度低)\n",
        "\n",
        "Now, picture is always more than 1000×1000 pixels, and each pixel has 3 RGB parameters to represent color information.\n",
        "\n",
        "###The amount of data to be processed is too large\n",
        "\n",
        "\n",
        "If we process a 1000×1000 pixel image, we need to process 3 million parameters!\n",
        "\n",
        "1000×1000×3=3,000,000\n",
        "\n",
        "<img src =\"https://developer.apple.com/design/human-interface-guidelines/ios/images/ImageResolution-Graphic_2x.png\" width =\"600\" />\n",
        "\n",
        "\n",
        "###Preserve image characteristics (保留圖像特徵)\n",
        "\n",
        "In the traditional digitization (傳統數字化), although only the position has changed, all the parameters obtained will be very different.\n",
        "\n",
        "<img src =\"https://processing.org/tutorials/pixels/imgs/pixelarray.jpg\"  width =\"800\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7O6yqWT0tNrZ"
      },
      "source": [
        "### 2B: Principle of Human Vision (人類視覺原理)\n",
        "\n",
        "1. Start from the original signal intake (the pupils (瞳孔) take in pixels Pixels),\n",
        "\n",
        "2. Then do preliminary processing (初步處理) (some cells in the cerebral cortex (大腦皮層) find edges and directions (邊緣和方向)), and then abstract (抽象) (the brain determines (判斷) that the shape of the object in front of you is circular),\n",
        "\n",
        "3. Then further abstract (抽象) (the brain further determines that the object is a balloon).\n",
        "\n",
        "The following is an example of face recognition by the human brain:\n",
        "\n",
        "<img src =\"https://easy-ai.oss-cn-shanghai.aliyuncs.com/2019-06-24-rennao.png\" width = \"600\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdD6iCp_yEVf"
      },
      "source": [
        "###2C: Basic principles of convolutional neural network-CNN (卷積神經網絡基本原理)\n",
        "\n",
        "A typical CNN consists of 3 parts:\n",
        "\n",
        "> 1. Convolutional layer (卷積層): The convolutional layer is responsible for extracting local features in the image (卷積層負責提取圖像中的局部特徵)\n",
        "\n",
        "> 2. Pooling layer (池化層): The pooling layer is used to greatly reduce the magnitude of parameters (池化層用於大幅度降低參數的量級) (dimensionality reduction)（降維）\n",
        "\n",
        "> 3. Fully connected layer (全連接層): The fully connected layer is similar to the part of the traditional neural network, used to output the desired result (全連接層類似於傳統神經網絡的部分，用於輸出想要的結果)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWx1nbSxyfsF"
      },
      "source": [
        "##2D: Convolution-extracting features (卷積提取特徵)\n",
        "\n",
        "The operation process of the convolutional layer is as shown in the figure below. Use a convolution kernel to scan the complete picture:\n",
        "\n",
        "\n",
        "<img src =\"https://easy-ai.oss-cn-shanghai.aliyuncs.com/2019-06-19-juanji.gif\n",
        "\" width = \"600\" />\n",
        "\n",
        "This process can be understood as we use a filter (convolution kernel) (濾波器（卷積核）) to filter each small area of the image, so as to obtain the feature value of these small areas.\n",
        "\n",
        "The convolutional layer extracts local features in the picture through the filtering of the convolution kernel, which is similar to the feature extraction of human vision mentioned above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVhWktngzAB-"
      },
      "source": [
        "###2E. Pooling layer (downsampling) (池化層（下採樣）) -data dimensionality reduction to avoid overfitting (數據降維，避免過擬合)\n",
        "\n",
        "The pooling layer is simply down-sampling, which can greatly reduce the dimensionality of the data. The process is as follows:\n",
        "\n",
        "<img src =\"https://easy-ai.oss-cn-shanghai.aliyuncs.com/2019-06-19-chihua.gif\n",
        "\" width = \"600\" />\n",
        "\n",
        "In the above figure, we can see that the original image is 20×20, we downsample it, the sampling window is 10×10, and finally it is downsampled into a 2×2 feature map.\n",
        "\n",
        "The reason for this is that even after the convolution is done, the image is still very large (because the convolution kernel is relatively small), so in order to reduce the data dimension, downsampling is performed.\n",
        "\n",
        "Summary: The pooling layer can reduce the data dimension more effectively than the convolutional layer. This can not only greatly reduce the amount of calculation (大大減少計算量), but also effectively avoid overfitting (避免過擬合)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBw32BQnzanZ"
      },
      "source": [
        "###2F. Fully connected layer (全連接層) -output results (輸出結果)\n",
        "\n",
        "This part is the last step. The data processed by the convolutional layer and the pooling layer is input to the fully connected layer to obtain the final desired result.\n",
        "\n",
        "After the dimensionality reduction of the convolutional layer and the pooling layer, the fully connected layer can \"run\". Otherwise, the amount of data is too large, the calculation cost is high, and the efficiency is low.\n",
        "\n",
        "<img src =\"https://iq.opengenus.org/content/images/2019/03/fc.jpg\n",
        "\" width = \"600\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5Brb7UlzmY9"
      },
      "source": [
        "###2G: CNN multi-layer structure (CNN多層結構)\n",
        "\n",
        "Convolutional layer >> Pooling layer >>Convolutional layer >> Pooling layer >> Convolutional layer >>Fully connected layer\n",
        "\n",
        "A typical CNN is not just the three-layer structure mentioned above, but a multi-layer structure. For example, the structure of LeNet-5 is as shown in the figure below:\n",
        "\n",
        "\n",
        "<img src =\"https://easy-ai.oss-cn-shanghai.aliyuncs.com/2019-06-19-lenet.png\n",
        "\" width = \"1000\" />\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4r6HUXBRIyL9"
      },
      "source": [
        "## 3: Classification of MNIST Dataset with Convolutional Neural Networks 使用卷積神經網絡對 MNIST 進行分類\n",
        "\n",
        "Next, let's build a convolutional neural network (CNN) classifier to classify images of handwritten digits (手寫數字) in the MNIST dataset with a twist where we test our classifier on high-resolution hand-written digits from outside the dataset.\n",
        "\n",
        "<img src=\"https://i.imgur.com/ITrm9x4.png\" width=\"800px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3xQ8JfP_Tvv"
      },
      "source": [
        "##Step 1: Importing The Libraries (導入庫)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TK_I80zGOJl6",
        "outputId": "f8cb150c-7b85-4e58-ee3f-47c05f842c25"
      },
      "source": [
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "\n",
        "# Commonly used modules\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Images, plots, display, and visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import IPython\n",
        "from six.moves import urllib\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_C4tJzs_WTb"
      },
      "source": [
        "##Step 2: Download the Dataset (下載數據集)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fY3Le3WcIyL-"
      },
      "source": [
        "1. The MNIST dataset containss 70,000 grayscale images of handwritten digits at a resolution of 28 by 28 pixels. \n",
        "\n",
        "2. The task is to take one of these images as input and predict the most likely digit contained in the image.\n",
        "\n",
        "3. Now, we load the dataset. The images are 28x28 NumPy arrays, with pixel values ranging between 0 and 255. \n",
        "\n",
        "4. The *labels* are an array of integers, ranging from 0 to 9."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AmA3fXmIyL-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba23fdd0-a0fe-4f9e-f246-d05699619099"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# reshape images to specify that it's a single channel\n",
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1)\n",
        "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)\n",
        "print(\"train images >>\")\n",
        "print(train_images.shape)\n",
        "print(\"train images >>\")\n",
        "print(test_images.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train images >>\n",
            "(60000, 28, 28, 1)\n",
            "train images >>\n",
            "(10000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaeQY8vaIyL_"
      },
      "source": [
        "1. We scale these values to a range of 0 to 1 before feeding to the neural network model. \n",
        "\n",
        "2. For this, we divide the values by 255. It's important that the *training set* and the *testing set* are preprocessed in the same way:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qri9ADiiIyMC"
      },
      "source": [
        "def preprocess_images(imgs): # should work for both a single image and multiple images\n",
        "    sample_img = imgs if len(imgs.shape) == 2 else imgs[0]\n",
        "    assert sample_img.shape in [(28, 28, 1), (28, 28)], sample_img.shape # make sure images are 28x28 and single-channel (grayscale)\n",
        "    return imgs / 255.0\n",
        "\n",
        "train_images = preprocess_images(train_images)\n",
        "test_images = preprocess_images(test_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca-7Q4ZaIyMD"
      },
      "source": [
        "Display the first 10 images from the *training set* and display the class name below each image. \n",
        "\n",
        "Verify that the data is in the correct format (驗證數據格式) and we're ready to build and train the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7Pa63YcIyMD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "937bd9bf-771a-47f2-d3cd-f18a72ebae19"
      },
      "source": [
        "plt.figure(figsize=(10,2))\n",
        "for i in range(10):\n",
        "    plt.subplot(1,10,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i].reshape(28, 28), cmap=plt.cm.binary)\n",
        "    plt.xlabel(train_labels[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x144 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEqUP9VsIyME"
      },
      "source": [
        "### Step 3: Build the model (構建模型)\n",
        "\n",
        "Building the neural network requires configuring the layers of the model, then compiling the model. In many cases, this can be reduced to simply stacking together layers:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOhuqrqnIyMF"
      },
      "source": [
        "model = keras.Sequential()\n",
        "# 32 convolution filters used each of size 3x3\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "# 64 convolution filters used each of size 3x3\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "# choose the best features via pooling\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# randomly turn neurons on and off to improve convergence\n",
        "model.add(Dropout(0.25))\n",
        "# flatten since too many dimensions, we only want a classification output\n",
        "model.add(Flatten())\n",
        "# fully connected to get all relevant data\n",
        "model.add(Dense(128, activation='relu'))\n",
        "# one more dropout\n",
        "model.add(Dropout(0.5))\n",
        "# output a softmax to squash the matrix into output probabilities\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvBanZqGIyMG"
      },
      "source": [
        "###Step4: Compile the model (編譯模型)\n",
        "\n",
        "Before the model is ready for training, it needs a few more settings. These are added during the model's *compile* step:\n",
        "\n",
        "* *Loss function* - measures how accurate the model is during training, we want to minimize this with the optimizer.\n",
        "\n",
        "* *Optimizer* - how the model is updated based on the data it sees and its loss function.\n",
        "\n",
        "* *Metrics* - used to monitor the training and testing steps. \"accuracy\" is the fraction of images that are correctly classified."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHvhBy3MIyMH"
      },
      "source": [
        "model.compile(optimizer=tf.optimizers.Adam() , \n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9ezGudFPC3T",
        "outputId": "3a19c99a-067d-419b-fc79-747d740ec86e"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               1179776   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,199,882\n",
            "Trainable params: 1,199,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ts97sk_-IyMH"
      },
      "source": [
        "### Step 5: Train the model (訓練模型)\n",
        "\n",
        "Training the neural network model requires the following steps:\n",
        "\n",
        "1. Feed the training data to the model—in this example, the `train_images` and `train_labels` arrays.\n",
        "\n",
        "2. The model learns to associate images and labels. (模型學習關聯圖像和標籤)\n",
        "\n",
        "3. We ask the model to make predictions about a test set—in this example, the `test_images` array. We verify that the predictions match the labels from the `test_labels` array. \n",
        "\n",
        "To start training,  call the `model.fit` method—the model is \"fit\" to the training data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YCO_dGsIyMI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be03f646-f49e-4b5f-ce23-8dff947fb986"
      },
      "source": [
        "history = model.fit(train_images, train_labels, epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 41s 7ms/step - loss: 0.2006 - accuracy: 0.9395\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0836 - accuracy: 0.9750\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0650 - accuracy: 0.9798\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0536 - accuracy: 0.9839\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0436 - accuracy: 0.9864\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3buFI7fIyMJ"
      },
      "source": [
        "As the model trains, the loss and accuracy metrics are displayed. This model reaches an accuracy of about 98.68% on the training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-g6eaERTQBw6"
      },
      "source": [
        "**Change Hardware accelerator to \"GPU\" in Runtime type**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNsipb3kL03-"
      },
      "source": [
        "###Step 5A:　AlexNet\n",
        "\n",
        "1. AlexNet is a deep network that was applied to ImageNet earlier, and its accuracy is greatly improved compared to traditional methods. \n",
        "\n",
        "2. It is first 5 convolutional layers, followed by 3 fully connected layers, as shown in the following figure:\n",
        "\n",
        "<img src =\"https://pic1.zhimg.com/80/v2-45715701e5ecea42d07f15fb3ae87100_hd.jpg\" width =\"800\" />\n",
        "\n",
        "\n",
        "3. The AlexNet proposed by Alex Krizhevs uses the ReLU activation function. \n",
        "\n",
        "4. The advantage of ReLU over Sigmoid is that its training speed is faster, because the derivative of Sigmoid will be very small in the stable region (導數在穩定區域會非常小), so the weight is basically no longer updated. \n",
        "\n",
        "5. This is the vanishing gradient (梯度消失) problem. \n",
        "\n",
        "6. Therefore, AlexNet uses ReLU after the convolutional layer and the fully connected layer.\n",
        "\n",
        "<img src =\"https://pic2.zhimg.com/80/v2-345af658efe0ec7c37675f712bdc536a_hd.jpg\" width =\"400\" />\n",
        "\n",
        "7. Another feature of AlexNet is that it reduces the over-fitting (過擬合) problem of the model by adding a Dropout layer after each fully connected layer. \n",
        "\n",
        "8. The Dropout layer randomly turns off the neuron activation value in the current layer with a certain probability, as shown in the following figure:\n",
        "\n",
        "<img src =\"https://pic2.zhimg.com/80/v2-10918053b1343097a52dcebcb93fb90b_hd.jpg\" width =\"600\" />\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWMS3P8pNFzH"
      },
      "source": [
        "###Step 5B:　VGG16\n",
        "\n",
        "1. VGG16 was proposed by the VGG group of Oxford University. \n",
        "\n",
        "2.An improvement of VGG16 over AlexNet is to use several consecutive 3x3 convolution kernels to replace the larger convolution kernels in AlexNet (11x11, 5x5). \n",
        "\n",
        "3. Using a stacked small convolution kernel is better than using a large convolution kernel, because multiple non-linear layers can increase the depth of the network to ensure more complex learning.\n",
        "\n",
        "4. The model, and the cost is relatively small (fewer parameters).\n",
        "\n",
        "5. The architecture of the VGG network is shown in the following table:\n",
        "\n",
        "<img src =\"https://pic4.zhimg.com/80/v2-e47b44f1c0cfd111c270f1a73d9d4d4d_hd.jpg\" width =\"800\" />\n",
        "\n",
        "6. After the VGG convolutional layer are 3 fully connected layers. \n",
        "\n",
        "7. The number of channels of the network starts from the smaller 64, and then increases exponentially (指數增長) after each down-sampling or pooling layer, and of course the size of the feature map decreases exponentially. \n",
        "\n",
        "8. In the end, its Top-5 accuracy on ImageNet was 92.3%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2ESUaWVNfn2"
      },
      "source": [
        "### Step 5C:　Inception\n",
        "\n",
        "1. Although VGG can perform very well on ImageNet, it is difficult to deploy it on a moderately sized GPU, because VGG requires high computational requirements in terms of memory and time (內存和時間). \n",
        "\n",
        "2. Because the number of channels in the convolutional layer is too large, VGG is not efficient. \n",
        "\n",
        "3. As mentioned earlier, only a few neurons are really effective, so the number of convolution kernels of a specific size is set very small. \n",
        "\n",
        "4. At the same time, GoogLeNet uses different sizes of convolution kernels to capture different sizes of receptive (感受) fields.\n",
        "<img src =\"https://pic2.zhimg.com/80/v2-bd51612135eb46290ae99885041b8015_hd.jpg\" width =\"800\" />\n",
        "\n",
        "5. Another special design of GoogLeNet is to replace the fully connected layer with a global average pooling layer after the final convolutional layer (全局平均池化層). \n",
        "\n",
        "6. The so-called global pooling is to take the average value on the entire 2D feature map (在整個二維特徵圖上取平均值). \n",
        "\n",
        "7. This greatly reduces the amount of total parameters of the model (減少了模型的總參數量). \n",
        "\n",
        "8. Using a deeper and larger network allows GoogLeNet to remove the fully connected layer (移除全連接層) without affecting accuracy. \n",
        "\n",
        "Its top-5 accuracy on ImageNet is 93.3%, but the speed is faster than VGG."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOYitp6kROsA"
      },
      "source": [
        "###Step 5D:　ResNet\n",
        "\n",
        "1. It can be seen from the front that as the network depth increases, the accuracy of the network should increase simultaneously (網絡的準確率應該同步增加). \n",
        "\n",
        "2. However, after increasing the network depth, the gradient of the higher layer will be very small (高層的梯度會很小). \n",
        "\n",
        "3. This means that the learning of these layers basically stagnates (學習基本停滯), which is the vanishing gradient problem (梯度消失). \n",
        "\n",
        "4. The second problem of the deep network is training. \n",
        "\n",
        "5. When the network is deeper, it means that the parameter space is larger and the optimization problem becomes more difficult (優化問題變得更加困難). \n",
        "\n",
        "6. Therefore, simply increasing the network depth will cause higher training errors (增加網絡深度會導致更高的訓練誤差). \n",
        "\n",
        "7. Residual network ResNet designed a residual module (殘差模塊) so that we can train a deeper network.\n",
        "\n",
        "<img src =\"https://i.stack.imgur.com/gI4zT.png\" width =\"1000\" />\n",
        "\n",
        "\n",
        "8. The training problem of the deep network is called the degradation problem. \n",
        "\n",
        "9. It is not easy for the added layer to learn the identity mapping (恆等映射). \n",
        "\n",
        "10. In order to solve this degradation problem, the residual module (殘差模塊) establishes a direct connection between the input and the output, so that the newly added layer  only needs to learn new features on the basis of the original input layer, which is easier to learn.\n",
        "\n",
        "11. Similar to GoogLeNet, ResNet finally uses the global mean pooling layer. Using the residual module, a 152-layer residual network can be trained. \n",
        "\n",
        "12. Its accuracy is higher than that of VGG and GoogLeNet, but its computational efficiency is also higher than that of VGG. \n",
        "\n",
        "13. The 152-layer ResNet has a top-5 accuracy of 95.51%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTrN23LIIyMK"
      },
      "source": [
        "### Step 6: Evaluate accuracy (評估準確性)\n",
        "\n",
        "Next, compare how the model performs on the test dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Qav3poFIyMK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fad24aaa-1df8-4e7b-990b-d5953cb5b7df"
      },
      "source": [
        "print(test_images.shape)\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 28, 28, 1)\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0290 - accuracy: 0.9917\n",
            "Test accuracy: 0.9916999936103821\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uq7tZjteIyML"
      },
      "source": [
        "1. Often times, the accuracy on the test dataset is a little less than the accuracy on the training dataset. \n",
        "\n",
        "2. This gap between training accuracy and test accuracy is an example of *overfitting*. \n",
        "\n",
        "3. In our case, the accuracy is better at 99.19%! \n",
        "\n",
        "4. This is, in part, due to successful regularization (正則化) accomplished with the Dropout layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPpwWKEHIyMM"
      },
      "source": [
        "### Step 7: Make predictions (作出預測)\n",
        "\n",
        "With the model trained, we can use it to make predictions about some images. \n",
        "\n",
        "![MNIST dream](https://i.imgur.com/OrUJs9V.gif)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "JTXHJt95FniU",
        "outputId": "04fb77c1-b183-4b20-d318-a3594a64b47b"
      },
      "source": [
        "# upload the dataset from local to google drive\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b379bfc2-1e98-41eb-9bcd-d38f522e4548\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b379bfc2-1e98-41eb-9bcd-d38f522e4548\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving png-transparent-logo-brand-black-and-white-number-9-text-logo-black.png to png-transparent-logo-brand-black-and-white-number-9-text-logo-black.png\n",
            "User uploaded file \"png-transparent-logo-brand-black-and-white-number-9-text-logo-black.png\" with length 5080 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBMouF3RGOAj"
      },
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "-GDpyihgFkNP",
        "outputId": "cbcd8b3b-8075-4390-eccd-8e4b840f4ac9"
      },
      "source": [
        "y=cv2.imread(\"/content/png-transparent-logo-brand-black-and-white-number-9-text-logo-black.png\")   \n",
        "#image outside mnist data\n",
        "y1=cv2.resize(y,(28,28))                \n",
        "#you need to resize it on the bsis pf your  modeL's image shape\n",
        "plt.imshow(y1)\n",
        "temp = cv2.cvtColor(y1,cv2.COLOR_BGR2YCrCb)\n",
        "#since its a three channel image i hav econverted into this so rbg are represented in the luminance one \n",
        "temp=255-temp                                \n",
        "#negative image\n",
        "plt.imshow(temp)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f05c88a85d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VwzR9aNKxEz",
        "outputId": "cc6f4696-7341-4b2e-c47b-31136d9fc5cc"
      },
      "source": [
        "  \n",
        "print(temp.shape)\n",
        "\n",
        "Y = np.zeros((temp.shape[0], temp.shape[1],1), dtype=float)    #array of (28,28,1)\n",
        "Y[:,:,0] = temp[:, :,0].astype(float) / 255           #fitting the data of temp image in that zeros and normalizing it\n",
        "yh= np.argmax(model.predict(Y.reshape(1,28,28,1)))\n",
        "print(yh)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28, 28, 3)\n",
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urckX_NZIyMO"
      },
      "source": [
        "Source:\n",
        "\n",
        "[Deep learning MIT](https://https://deeplearning.mit.edu)\n",
        "        \n",
        "\n",
        "https://easyai.tech/ai-definition/cnn/        "
      ]
    }
  ]
}